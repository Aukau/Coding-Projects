{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e561f2-a6d5-42b9-b44b-647f13767752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "\n",
    "# Qiskit and maths\n",
    "import numpy as np\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit.circuit.library import Initialize, QFT, TwoLocal\n",
    "from qiskit_aer.primitives import Sampler\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Finance information\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Extras :)\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f4f056-9b57-4d1e-bf3f-f406166d6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class qGAN:\n",
    "    \"\"\"\n",
    "        This class implements the Quantum Generative Adversarial Network based on the paper in nature\n",
    "        ```Quantum Generative Adversarial Networks for learning and loading random distributions``` \n",
    "        from Zoufal, Lucchi, and Woerner (https://www.nature.com/articles/s41534-019-0223-2#ref-CR32).\n",
    "\n",
    "        The techniques this class implements that the paper either doesn't mention or doesn't include\n",
    "        are: TwoLocal circuit preparation, prioritising generator training (roughly twice as often as \n",
    "        the discriminator), label smoothing, explicit binary cross entropy with real and fake loss for\n",
    "        the discriminator, gradient clipping for the disc and genr, both KL and Entropy regularisation\n",
    "        to optimise for quantum states (still helpful for classical problems). We also do some \n",
    "        post-calculations including, KL divergence, Entropy, Coverage, and Loss with graphs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, model, samples, rotation_gate='ry', entangle_gate='cz', epochs=100, num_samples=1000, n_qubits=6, k_layers=3,\n",
    "            batch_size=32, gen_lr=2e-4, disc_lr=1e-4, bounds=[-1.5, 1.5], sampler=Sampler(), device='cpu', circuit=None,\n",
    "                ):\n",
    "        # Problem specific variables\n",
    "        self.num_samples = num_samples # Ideally around 1000 samples or more\n",
    "        self.n_qubits = n_qubits       # A good range is 4 - 8 qubits\n",
    "        self.k_layers = k_layers       # Best around 2 - 3 repititions\n",
    "        self.model = model             # torch.nn.Sequential: linear, leakyReLU, linear, Sigmoid (Might be improved in the future)\n",
    "        self.samples = samples         # A torch tensor float 32 that matches the target distribution\n",
    "        self.batch_size = batch_size   # Batching data into roughly 32, optimises runtime\n",
    "        self.gen_lr = gen_lr           # Keep this a bit higher than the disc_lr\n",
    "        self.disc_lr = disc_lr         # Around 5e-5 to 1e-4, this should not overpower the generator\n",
    "        self.bounds = bounds           # Problem specific, but this is just generally for the QFT state prep. problem\n",
    "        self.epochs = epochs           # Best to have around 300, if you have 100 a quantum state will not be properly learnt\n",
    "        self.sampler = sampler         # Base use is the qiskit simulator sampler\n",
    "        self.device = device           # Option of cpu or gpu\n",
    "        self.func = circuit            # In case people want to build something other than a TwoLocal circuit\n",
    "        # Ansatz specific gates\n",
    "        self.rot_gate = rotation_gate\n",
    "        self.ent_gate = entangle_gate\n",
    "\n",
    "        # Standard/Computed Variables\n",
    "        self.epsilon = 1e-8\n",
    "        bins = 2 ** self.n_qubits\n",
    "        self.QC_TEMPLATE, self.NOISE_PARAMS, self.ANSATZ_PARAMS = None, None, None # build_parameterized_circuit in model initialisation\n",
    "        self.dummy_ansatz = None # Basic TwoLocal for this case based on rotation gates\n",
    "        self.num_ansatz_params = None # Based on dummy ansatz params\n",
    "        self.theta = None # Defined in the initialisation\n",
    "        self.num_params = None # Defined in the intialisation\n",
    "        self.dataloader = DataLoader(TensorDataset(self.samples), batch_size=32, shuffle=True)\n",
    "\n",
    "        self.initialise_model() # Fixing the None variables\n",
    "\n",
    "    \n",
    "    def build_parameterised_circuit(self, build_func=None):\n",
    "        \"\"\"\n",
    "            This function builds the parameterised circuit with either TwoLocal or the users choice.\n",
    "        \"\"\"\n",
    "        noise_params = ParameterVector(\"ζ\", length=self.n_qubits)\n",
    "        \n",
    "        ansatz = build_func if build_func else TwoLocal(\n",
    "            self.n_qubits, self.rot_gate, self.ent_gate,\n",
    "            reps=self.k_layers, entanglement='circular', parameter_prefix=\"θ\"\n",
    "        )\n",
    "        \n",
    "        qc = QuantumCircuit(self.n_qubits)\n",
    "        \n",
    "        for i in range(self.n_qubits):\n",
    "            qc.ry(noise_params[i], i)\n",
    "        \n",
    "        qc.compose(ansatz, inplace=True)\n",
    "        qc.measure_all()\n",
    "        \n",
    "        return qc, list(noise_params), list(ansatz.parameters)\n",
    "\n",
    "    \n",
    "    def generator_update(self, noise_batch):\n",
    "        \"\"\"\n",
    "            This is a function that updates the generator based on the noise, with clipping.\n",
    "        \"\"\"\n",
    "        shift = np.pi / 2\n",
    "        grad = torch.zeros_like(self.theta)\n",
    "        batch_size = noise_batch.size(0)\n",
    "        ones = torch.ones((batch_size, 1)).to(self.device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for i in range(self.num_params):\n",
    "                theta_plus = self.theta.clone()\n",
    "                theta_plus[i] += shift\n",
    "                theta_minus = self.theta.clone()\n",
    "                theta_minus[i] -= shift\n",
    "    \n",
    "                g_plus = self.quantum_generator(noise_batch, theta_plus)\n",
    "                g_minus = self.quantum_generator(noise_batch, theta_minus)\n",
    "    \n",
    "                D_plus = self.model(g_plus)\n",
    "                D_minus = self.model(g_minus)\n",
    "    \n",
    "                loss_plus = F.binary_cross_entropy(D_plus, ones)\n",
    "                loss_minus = F.binary_cross_entropy(D_minus, ones)\n",
    "    \n",
    "                grad[i] = ((loss_plus - loss_minus) / 2).clamp(-1.0, 1.0)\n",
    "    \n",
    "            self.theta -= self.gen_lr * grad\n",
    "\n",
    "                         \n",
    "    def build_func(self):\n",
    "        '''\n",
    "            Just a short function in case peopole want to use something other than TwoLocal.\n",
    "            Returns a the circuit with the rotation and entanglements.\n",
    "        '''\n",
    "        if not self.func:\n",
    "            return TwoLocal(self.n_qubits, self.rot_gate, self.ent_gate, reps=self.k_layers, entanglement='circular')\n",
    "        return func(self.n_qubits, self.rot_gate, self.ent_gate, self.k_layers)\n",
    "\n",
    "\n",
    "    def quantum_generator(self, noise_batch, theta):\n",
    "        '''\n",
    "            This is the main portion of our qGAN model which runs the sampler on the quantum\n",
    "            circuit to get batch_outputs for results.\n",
    "        '''\n",
    "        batch_size = noise_batch.shape[0]\n",
    "        flat_theta = theta.detach().cpu().numpy()\n",
    "    \n",
    "        noise_np = noise_batch.detach().cpu().numpy()\n",
    "        lower, upper = self.bounds\n",
    "        noise_angles = (noise_np + 1) / 2 * (upper - lower) + lower\n",
    "    \n",
    "        parameter_values = []\n",
    "        for i in range(batch_size):\n",
    "            noise_vec = noise_angles[i][:len(self.NOISE_PARAMS)]\n",
    "            theta_vec = flat_theta[:len(self.ANSATZ_PARAMS)]\n",
    "            parameter_values.append(list(noise_vec) + list(theta_vec))\n",
    "    \n",
    "        results = self.sampler.run([self.QC_TEMPLATE] * batch_size, parameter_values=parameter_values, shots=2048).result()\n",
    "        batch_outputs = []\n",
    "        dim = 2 ** self.n_qubits\n",
    "        for dist in results.quasi_dists:\n",
    "            hist = np.zeros(dim)\n",
    "            for bitstring, prob in dist.items():\n",
    "                idx = int(bitstring, 2) if isinstance(bitstring, str) else int(bitstring)\n",
    "                hist[idx] = prob\n",
    "            batch_outputs.append(hist)\n",
    "    \n",
    "        batch_outputs = np.stack(batch_outputs, axis=0).astype(np.float32)\n",
    "        return torch.tensor(batch_outputs, dtype=torch.float32, device=self.device)\n",
    "        \n",
    "    \n",
    "    def initialise_model(self):\n",
    "        # Necessary params\n",
    "        self.QC_TEMPLATE, self.NOISE_PARAMS, self.ANSATZ_PARAMS = self.build_parameterised_circuit()\n",
    "        self.dummy_ansatz = self.build_func()\n",
    "        self.num_ansatz_params = len(self.dummy_ansatz.parameters)\n",
    "        self.theta = nn.Parameter(torch.rand(len(self.ANSATZ_PARAMS), dtype=torch.float32, requires_grad=True).to(self.device))\n",
    "        self.num_params = len(self.theta)\n",
    "\n",
    "    def train(self):\n",
    "        ######## MAKE SURE QUANTUM_GENERATOR FUNCTIONS TAKE NEW INPUTS\n",
    "        '''\n",
    "        This is the function to train the model.\n",
    "        '''\n",
    "        gen_losses, disc_losses, kl_divs, entropies, mode_coverages = [], [], [], [], []\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        bins = 2 ** self.n_qubits\n",
    "        dis_opt = optim.Adam(self.model.parameters(), lr=self.disc_lr, amsgrad=True)\n",
    "    \n",
    "        for epoch in range(self.epochs):\n",
    "            for real_data_batch in tqdm(self.dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "                real_data = real_data_batch[0].to(self.device)\n",
    "                batch_size = real_data.size(0)\n",
    "    \n",
    "                # Train Discriminator\n",
    "                dis_opt.zero_grad()\n",
    "                real_loss = F.binary_cross_entropy(self.model(real_data), torch.full((batch_size,1),0.8).to(self.device))\n",
    "    \n",
    "                noise = torch.randn(batch_size, self.n_qubits).to(self.device)\n",
    "                fake_data = self.quantum_generator(noise, self.theta).detach()\n",
    "                fake_loss = F.binary_cross_entropy(self.model(fake_data), torch.full((batch_size,1),0.2).to(self.device))\n",
    "    \n",
    "                disc_loss = real_loss + fake_loss\n",
    "                disc_loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                dis_opt.step()\n",
    "    \n",
    "                # Generator updates (twice as frequent)\n",
    "                for _ in range(2):\n",
    "                    noise = torch.randn(batch_size, self.n_qubits).to(self.device)\n",
    "                    fake_preds = self.model(self.quantum_generator(noise, self.theta))\n",
    "                    gen_loss = F.binary_cross_entropy(fake_preds, torch.full((batch_size,1),0.9).to(self.device))\n",
    "    \n",
    "                    with torch.no_grad():\n",
    "                        real_dist = real_data.mean(dim=0) + self.epsilon\n",
    "                        gen_dist = fake_data.mean(dim=0) + self.epsilon\n",
    "                        kl_reg = F.kl_div((gen_dist/gen_dist.sum()).log(), real_dist/real_dist.sum(), reduction='batchmean')\n",
    "                        entropy = -(gen_dist/gen_dist.sum() * (gen_dist/gen_dist.sum()).log()).sum()\n",
    "    \n",
    "                    gen_loss += 0.25 * kl_reg - 0.01 * entropy\n",
    "                    self.generator_update(noise)\n",
    "    \n",
    "            gen_losses.append(gen_loss.item())\n",
    "            disc_losses.append(disc_loss.item())\n",
    "\n",
    "    \n",
    "            # === KL Divergence, Entropy, Mode Coverage ===\n",
    "            noise = torch.randn(1000, self.n_qubits).to(self.device)\n",
    "            fake_samples = self.quantum_generator(noise, self.theta).detach().to(self.device)\n",
    "            fake_flat = fake_samples.mean(dim=0)\n",
    "            real_flat = real_data[:len(fake_samples)].mean(dim=0).to(self.device)\n",
    "    \n",
    "            fake_prob = fake_flat / fake_flat.sum() + self.epsilon\n",
    "            real_prob = real_flat / real_flat.sum() + self.epsilon\n",
    "    \n",
    "            kl = F.kl_div(fake_prob.log(), real_prob, reduction='batchmean')\n",
    "            entropy = -torch.sum(fake_prob * fake_prob.log()).item()\n",
    "            mode_coverage = (fake_prob > 1e-3).sum().item()\n",
    "    \n",
    "            kl_divs.append(kl.item())\n",
    "            entropies.append(entropy)\n",
    "            mode_coverages.append(mode_coverage)\n",
    "    \n",
    "            # === Combined LIVE PLOTS ===\n",
    "            clear_output(wait=True)\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(18, 4))\n",
    "    \n",
    "            axs[0].plot(gen_losses, label=\"Generator\")\n",
    "            axs[0].plot(disc_losses, label=\"Discriminator\")\n",
    "            axs[0].set_title(\"Losses\")\n",
    "            axs[0].legend()\n",
    "            axs[0].grid(True)\n",
    "    \n",
    "            axs[1].plot(kl_divs, label=\"KL(G || R)\", color='purple')\n",
    "            axs[1].set_title(\"KL Divergence\")\n",
    "            axs[1].legend()\n",
    "            axs[1].grid(True)\n",
    "    \n",
    "            real_indices = np.random.choice(np.arange(bins), p=real_prob.numpy(), size=1000)\n",
    "            fake_indices = np.random.choice(np.arange(bins), p=fake_prob.numpy(), size=1000)\n",
    "            axs[2].hist(real_indices, bins=bins, alpha=0.5, label=\"Real\", density=True)\n",
    "            axs[2].hist(fake_indices, bins=bins, alpha=0.5, label=\"Generated\", density=True)\n",
    "            axs[2].set_title(\"Distribution Comparison\")\n",
    "            axs[2].legend()\n",
    "            axs[2].grid(True)\n",
    "    \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "            print(f\"Epoch [{epoch+1}/{self.epochs}]  D_loss: {disc_loss.item():.4f}  G_loss: {gen_loss.item():.4f}  KL: {kl.item():.4f}  Entropy: {entropy:.4f}  Coverage: {mode_coverage}/{bins}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6384770-c273-48ad-b2ea-d8134b593639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create QFT States ===\n",
    "# Create QFT states\n",
    "n_qubits = 6\n",
    "\n",
    "# Initialize basis state |x⟩ = |5⟩ for example (can be any 0–7)\n",
    "x = 5\n",
    "qc = QuantumCircuit(n_qubits)\n",
    "qc.initialize([0]*x + [1] + [0]*(2**n_qubits - x - 1), range(n_qubits))\n",
    "\n",
    "# Apply QFT\n",
    "qft = QFT(num_qubits=n_qubits, do_swaps=False).decompose()\n",
    "qc.append(qft, range(n_qubits))\n",
    "\n",
    "# Simulate\n",
    "sv = Statevector.from_instruction(qc)\n",
    "\n",
    "# Measurement probabilities\n",
    "probs = sv.probabilities_dict()\n",
    "\n",
    "# Turn into vector over 2^n bins\n",
    "target_distribution = np.zeros(2**n_qubits)\n",
    "for bitstring, prob in probs.items():\n",
    "    idx = int(bitstring, 2)\n",
    "    target_distribution[idx] = prob\n",
    "\n",
    "# Convert to torch tensor\n",
    "real_data = torch.tensor(target_distribution, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae5ba2-1e50-4cc5-af5b-8ace01b18f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare samples\n",
    "num_samples = 1000\n",
    "samples_np = np.tile(target_distribution, (num_samples, 1))\n",
    "samples = torch.tensor(samples_np, dtype=torch.float32)\n",
    "\n",
    "# Create discriminator model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2**6, 20),\n",
    "    nn.LeakyReLU(0.01),\n",
    "    nn.Linear(20, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec8977c-1a32-40b8-951c-fbeda95ddca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model\n",
    "qgan = qGAN(model=model, samples=samples)\n",
    "qgan.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qiskit (stable)",
   "language": "python",
   "name": "qiskit-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
